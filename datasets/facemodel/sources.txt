1. Introduction

In this document we describe how to replicate our high-resolution face
database.

2. Image Acquisition

There are four data sources. For each source we describe below how to
acquire the images. Cite the relevant papers if you use these sources
in a publication.

CelebA: Download the in-the-wild high-res images from
http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html. Look in filelist.txt
for the 31043 images we used.

Helen: Download the images from
http://www.ifp.illinois.edu/~vuongle2/helen/. Look in filelist.txt for
the 1853 images we used.

MegaFace: Register then download identities_0.tar.gz training images
from http://megaface.cs.washington.edu/. Look in filelist.txt for the
50000 images we used.

LFW-Google: These are Internet photos found by searching with Google
Images. Note: the directory names are not the identities --- they are
the search terms. Look in lfwgoogle_url.txt for the 49868 original URLs.

3. Image Processing

(Optional) Loosely crop the images to the face (this will reduce I/O).

Copy the (cropped) images to $(DFI_ROOT)/images/facemodel then run
database_rebuild.py. This will take a very long time (hours).

At the end of the first run you will be prompted to remove bad images
(including images where the face detector failed) and duplicate
images. Answer "yes" both times. If you deleted any images then you will
need to rerun database_rebuild.py. It should take less than a minute to
remove the deleted images from the database.

